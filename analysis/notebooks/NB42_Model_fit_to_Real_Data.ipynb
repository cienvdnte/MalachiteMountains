{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/importlib/_bootstrap_external.py:426: ImportWarning: Not importing directory /home/ekaterina/Documents/001_Science/Flares_in_Clusters_II/flaresinclustersii/lib/python3.6/site-packages/mpl_toolkits: missing __init__\n",
      "  _warnings.warn(msg.format(portions[0]), ImportWarning)\n",
      "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from astropy.constants import R_sun, R_jup\n",
    "import astropy.units as u\n",
    "\n",
    "import os\n",
    "import copy\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from funcs.model import full_model, aflare, calculate_specific_flare_flux, aflare, calculate_angular_radius\n",
    "from funcs.flarefit import log_probability, log_probability_2flares, log_probability_2flares2ars\n",
    "from funcs.helper import calculate_inclination\n",
    "\n",
    "CWD = \"/\".join(os.getcwd().split(\"/\")[:-2])\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "\n",
    "import time\n",
    "tstamp = time.strftime(\"%d_%m_%Y_%H_%M\", time.localtime())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'28_02_2020_05_53'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tstamp = '13_12_2019_10_18'\n",
    "tstamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1733333333333333"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.132/2.7*24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sin(i)=0.9051468538161039\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ID                             277539431\n",
       "QCS                                   12\n",
       "typ                                  slc\n",
       "cadence_min                            2\n",
       "mission                             tess\n",
       "prefix                               TIC\n",
       "origin                            custom\n",
       "h_mission                           TESS\n",
       "SpT                                   M7\n",
       "view_start                          1641\n",
       "view_stop                         1643.5\n",
       "view_min                             750\n",
       "view_max                             970\n",
       "BJDoff                           2457000\n",
       "tstart                           1641.84\n",
       "ampl_min                             0.9\n",
       "ampl_max                             1.7\n",
       "RA                               163.815\n",
       "Dec                             -73.9364\n",
       "J                                  10.63\n",
       "R                                    NaN\n",
       "Gaia_G                           14.7381\n",
       "vsini_kms                             70\n",
       "e_vsini_kms                          7.5\n",
       "Prot_d                             0.095\n",
       "sini                                 NaN\n",
       "Ref                            this work\n",
       "identifier     WISEA J105515.71-735611.3\n",
       "Rstar                                NaN\n",
       "idtyp                               tess\n",
       "id                             277539431\n",
       "st                                    M7\n",
       "desig_2mass             10551532-7356091\n",
       "dist                             13.7047\n",
       "dist_err                        0.106872\n",
       "dist_source                         gaia\n",
       "rad                             0.145216\n",
       "rad_err                       0.00437047\n",
       "tflux                        5.01119e-11\n",
       "tfluxerr                     4.61344e-12\n",
       "tlum                         1.12637e+30\n",
       "tlumerr                      1.05174e+29\n",
       "kflux                        1.38073e-11\n",
       "kfluxerr                     1.51724e-12\n",
       "klum                         3.10348e+29\n",
       "klumerr                      3.44449e+28\n",
       "gmag                             14.7381\n",
       "jmag                               10.63\n",
       "kmag                               9.666\n",
       "Name: 3, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lcs = pd.read_csv(f\"{CWD}/data/summary/lcs.csv\")\n",
    "\n",
    "props = pd.read_csv(f\"{CWD}/data/summary/properties.csv\")\n",
    "\n",
    "lcs = lcs.merge(props, left_on=\"ID\", right_on=\"id\")\n",
    "\n",
    "\n",
    "lcs.to_csv(f\"{CWD}/data/summary/everything.csv\", index=False)\n",
    "target = lcs.iloc[3]\n",
    "target.Prot_d = target.Prot_d/2\n",
    "i_mu, i_sigma = calculate_inclination(target)\n",
    "i_mu, i_sigma = i_mu.to(\"rad\").value, i_sigma.to(\"rad\").value\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_mu/np.pi*180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from altaipony.altai import find_iterative_median\n",
    "from altaipony.flarelc import FlareLightCurve\n",
    "#from funcs.custom_detrending import refine_detrended_flux_err\n",
    "from funcs.multiperiod import remove_sinusoidal, fetch_lightcurve\n",
    "\n",
    "flck = fetch_lightcurve(target)\n",
    "\n",
    "t, sflux, model, period = remove_sinusoidal(target, plot=True, save=False,)# cut=[target.view_start-5,target.view_stop+5])\n",
    "print(t)\n",
    "F = FlareLightCurve(time=t, detrended_flux=sflux, \n",
    "                    detrended_flux_err=np.array(len(t)*[np.nanmean(flck.flux_err)]))\n",
    "print(F.detrended_flux_err)\n",
    "flcd = F#refine_detrended_flux_err(F, mask_pos_outliers_sigma=1.5, \n",
    "                                    # std_rolling_window_length=15, pad=25)\n",
    "\n",
    "choice = (t > target.view_start +.25) & (t < target.view_stop-.25) # only one flare in TIC 237 : + 1.56 - 1.\n",
    "t = t[choice]\n",
    "flux = sflux[choice]\n",
    "flux_err = np.nanmean(flcd.detrended_flux_err)\n",
    "median = np.nanmean(find_iterative_median(F).it_med-10)\n",
    "phi = (t - t[0])/target.Prot_d * 2 * np.pi\n",
    "\n",
    "pd.DataFrame({\"phi\":phi,\"flux\":flux, \"t\":t,\n",
    "              \"flux_err\":flux_err, \"median_\":median}).to_csv(f\"{CWD}/data/lcs/{tstamp}_{target.ID}.csv\",\n",
    "                                                             index=False)\n",
    "median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc = pd.read_csv(f\"{CWD}/data/lcs/{tstamp}_{target.ID}.csv\")\n",
    "phi = lc.phi.values\n",
    "flux = lc.flux.values\n",
    "flux_err = lc.flux_err.values\n",
    "t= lc.t.values\n",
    "median = lc.median_[0]\n",
    "median\n",
    "plt.plot(lc.t, lc.flux)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "phi_a = (target.tstart- t[0]-.0275)/target.Prot_d * 2 * np.pi\n",
    "theta_a = 15*np.pi/180#target.theta_a_init\n",
    "a = 2.6\n",
    "fwhm =  .03/target.Prot_d * 2 * np.pi\n",
    "qlum = target.tlum * u.erg/u.s\n",
    "R = target.rad * R_sun\n",
    "phi0 = -180* np.pi / 180\n",
    "Fth = calculate_specific_flare_flux(\"TESS\", flaret=1e4)\n",
    "phi_a_max = phi[-1]\n",
    "#plt.plot(phi,flux)\n",
    "radius = calculate_angular_radius(Fth, a, qlum, R,)\n",
    "theta_a, i_mu, phi_a, radius\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.plot(phi,flux)\n",
    "for i in range(-180,180,10):\n",
    "    plt.plot(phi, full_model(phi_a, theta_a, a, fwhm, i_mu, phi0=i* np.pi / 180,\n",
    "               phi=phi, num_pts=50, qlum=qlum,\n",
    "               Fth=Fth, R=R, median=median), c=\"r\", alpha=.31,)\n",
    "plt.plot(phi, full_model(phi_a, theta_a, a, fwhm, i_mu, phi0=phi0,\n",
    "           phi=phi, num_pts=50, qlum=qlum,\n",
    "           Fth=Fth, R=R, median=median), c=\"k\", alpha=1,)\n",
    "plt.ylim(2300,2700)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save inits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_probs = {\"log_probability\":[6, log_probability],\n",
    "             \"log_probability_2flares\":[9, log_probability_2flares],\n",
    "             \"log_probability_2flares2ars\":[10, log_probability_2flares2ars],}\n",
    "\n",
    "log_prob = \"log_probability\"\n",
    "nparam = log_probs[log_prob][0]\n",
    "\n",
    "with open(f\"{CWD}/data/summary/inits.csv\", \"a\") as f:\n",
    "    firstout = (\"date,ID,phi_a,theta_a,a,fwhm,Fth,phi0,\"\\\n",
    "                \"i_mu,i_sigma,radius_deg,R_Rsun,qlum_erg_s,\"\\\n",
    "                \"median,log_prob,nparam\\n\")\n",
    "    out = (f\"{tstamp},{target.ID},{phi_a},{theta_a},{a},{fwhm},{Fth.value},\"\\\n",
    "           f\"{phi0},{i_mu},{i_sigma},{radius},{(R/R_sun).value},{qlum.value},\"\\\n",
    "           f\"{median},{log_prob},{nparam}\\n\")\n",
    "   # f.write(firstout)\n",
    "    f.write(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run MCMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from funcs.flarefit import (log_probability,\n",
    "                            log_probability_2flares,\n",
    "                            log_probability_2flares2ars)\n",
    "\n",
    "log_probs = {\"log_probability\":[6, log_probability],\n",
    "             \"log_probability_2flares\":[9, log_probability_2flares],\n",
    "             \"log_probability_2flares2ars\":[10, log_probability_2flares2ars],}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Keyword arguments Nsteps = 50000\n",
    "\n",
    "def run_mcmc(Nsteps=50000, wiggle=1e-3):\n",
    "\n",
    "    inits = pd.read_csv(f\"{CWD}/data/summary/inits.csv\")\n",
    "    target = inits.loc[inits.ID == ID,:]\n",
    "    ndim = target.nparam\n",
    "    nwalkers = 32\n",
    "\n",
    "\n",
    "    inits = np.array([phi_a, theta_a, a, fwhm, i_mu, phi0]) \n",
    "    pos = inits * (1. + wiggle * np.random.randn(nwalkers, target.nparam))\n",
    "\n",
    "    # Set up the backend\n",
    "    # Don't forget to clear it in case the file already exists\n",
    "    filename = f\"{CWD}/analysis/results/mcmc/{tstamp}_{target.ID}_MCMC.h5\"\n",
    "    backend = emcee.backends.HDFBackend(filename)\n",
    "    backend.reset(nwalkers, ndim)\n",
    "\n",
    "\n",
    "    sampler = emcee.EnsembleSampler(nwalkers, target.nparam, log_probability,\n",
    "                                    args=(phi, flux, flux_err, target.qlum,\n",
    "                                          target.Fth, target.R_Rsun, target.median,\n",
    "                                          {\"i_mu\":target.i_mu,\n",
    "                                          \"i_sigma\":target.i_sigma}),\n",
    "                                    backend=backend)\n",
    "\n",
    "    sampler.run_mcmc(pos, Nsteps, progress=True, store=True);\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "# Read ID from keyboard here\n",
    "\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from funcs.flarefit import log_probability\n",
    "ndim = 6\n",
    "nwalkers = 32\n",
    "\n",
    "\n",
    "inits = np.array([phi_a, theta_a, a, fwhm, i_mu, phi0]) \n",
    "pos = inits * (1. + 1e-3 * np.random.randn(nwalkers, ndim))\n",
    "\n",
    "# Set up the backend\n",
    "# Don't forget to clear it in case the file already exists\n",
    "filename = f\"{CWD}/analysis/results/mcmc/{tstamp}_{target.ID}_MCMC.h5\"\n",
    "backend = emcee.backends.HDFBackend(filename)\n",
    "backend.reset(nwalkers, ndim)\n",
    "\n",
    "\n",
    "sampler = emcee.EnsembleSampler(nwalkers, ndim, log_probability,\n",
    "                                args=(phi, flux, flux_err, qlum, Fth, R, median, {\"i_mu\":i_mu,\n",
    "                                      \"i_sigma\":i_sigma}),\n",
    "                                backend=backend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"MCMC run at {tstamp}\\n\\nlight curve file: {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resume MCMC after break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = f\"{CWD}/analysis/results/mcmc/{tstamp}_{target.ID}_MCMC.h5\"\n",
    "\n",
    "new_backend = emcee.backends.HDFBackend(filename)\n",
    "print(\"Initial size: {0}\".format(new_backend.iteration))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tstamp, target.ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sampler = emcee.EnsembleSampler(nwalkers, ndim, log_probability, \n",
    "                                    args=(phi, flux, flux_err, \n",
    "                                          qlum, Fth, R, median, \n",
    "                                          {\"i_mu\":i_mu, \"i_sigma\":i_sigma, }),\n",
    "                                    backend=new_backend)\n",
    "new_sampler.run_mcmc(None, 50000, progress=True, store=True)\n",
    "print(\"Final size: {0}\".format(new_backend.iteration))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flaresinclustersii",
   "language": "python",
   "name": "flaresinclustersii"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
